When I ran @debug_pipeline.py

– Debug –
1. Preprocessing image...
  - PROCESSED_IMAGE shape: (1, 3, 640, 640)
  - Saved visualization to /tmp/phone_img_1_preprocessed.jpg {WORKS}

2. RTMDet detection...
  - dets shape: (1, 300, 5)
  - labels shape: (1, 300)
  - Saved visualization to /tmp/phone_img_2_detections.jpg {WORKS}

3. Person cropper...
  - cropped_person shape: (1, 3, 256, 192)
  - Saved visualization to /tmp/phone_img_3_cropped_person.jpg {WORKS}

4. RTMPose estimation...
  - simcc_x shape: (1, 17, 384)
  - simcc_y shape: (1, 17, 512)
  - Saved visualization to /tmp/phone_img_4_pose.jpg {WORKS}

5. Feature normalizer...
  - normalized_features shape: (1, 51)
DEBUG: Normalized Features Array: {also correct}
[[0.5822454  0.444227   0.5535248  0.26810175 0.5613577  0.27201566
  0.1462141  0.2935421  0.53524804 0.34050882 0.     	0.5107632
  0.50130546 0.40508807 0.767624   0.72602737 0.76501304 0.74168295
  1.     	1.     	1.     	1.     	0.     	0.
  0.3394256  0.43444228 0.73368144 0.7064579  0.72584856 0.68101764
  0.     	1.     	1.     	1.     	0.8537859  0.73189825
  0.57310706 0.6340509  0.6248844  0.8572386  0.     	0.
  0.     	0.     	0.     	0.     	0.     	0.
  0.     	0.     	0.    	]]

6. MLP phone detector...
  - mlp_logits: [[-0.00655777  0.03744017]] {This is wrong because mismatch in RTMDet/Pose and my training MMPoseInferencer(human)
--- Debugging pipeline for /app/deployment/test_images/nophone.jpg ---
1. Preprocessing image...
  - PROCESSED_IMAGE shape: (1, 3, 640, 640)
  - Saved visualization to /tmp/nophone_1_preprocessed.jpg

2. RTMDet detection...
  - dets shape: (1, 300, 5)
  - labels shape: (1, 300)
  - Saved visualization to /tmp/nophone_2_detections.jpg

3. Person cropper...
  - cropped_person shape: (1, 3, 256, 192)
  - Saved visualization to /tmp/nophone_3_cropped_person.jpg

4. RTMPose estimation...
  - simcc_x shape: (1, 17, 384)
  - simcc_y shape: (1, 17, 512)
  - Saved visualization to /tmp/nophone_4_pose.jpg

5. Feature normalizer...
  - normalized_features shape: (1, 51)
DEBUG: Normalized Features Array:
[[0.44386423 0.13111547 0.48041776 0.10958904 0.4151436  0.10958904
  0.53524804 0.11350293 0.38120106 0.11350293 0.6057441  0.19765167
  0.33420366 0.21330725 0.8328982  0.27005872 0.23759791 0.2935421
  0.7310705  0.26810175 0.18015666 0.369863   0.56657964 0.45401174
  0.3707572  0.45792565 0.65796345 0.5812133  0.26370758 0.5068493
  0.6997389  0.7808219  0.24281985 0.7847358  0.6527415  0.67514676
  0.5065274  0.44716242 0.44069633 1.0343249  0.     	0.
  0.     	0.     	0.     	0.     	0.     	0.
  0.     	0.     	0.    	]]

6. MLP phone detector...
  - mlp_logits: [[-0.04499059  0.08350593]]


So my first thought was to see if my MMPoseInferencer(human) that I've used in training matches what I'm using in my Triton (RTMDet and RTMPose) which it does (as I verified it from mmpose.apis) you can test this yourself and see.


Actually MMPOseInferencer(human) uses RTMPose and RTMDet only (verified from python)

The real problem::
During training (data_collector.py)

I used MMPoseInferencer('human').
That internally ran RTMDet (for person detection) + RTMPose (for keypoints), but then you took the keypoints and applied your own custom normalization:
Centered all keypoints around the neck (mid-shoulder).
Scaled them by shoulder/hip distance.
Appended the confidence score.
→ Resulting in 51-dim feature vectors used to train your MLP.


During inference (Triton pipeline)


You swapped in an rtmpose_estimation model that outputs simcc_x / simcc_y heatmaps.
Your first feature_normalizer implementation just took argmaxes or bounding-box stats → this did not match the training-time normalization.
So your MLP was being fed a different “language” of features than it had ever seen before.
That’s why the logits looked like weak noise ([-0.04, 0.08]) instead of confidently separating phone vs no-phone.

So there is a mismatch.
I need to make sure my feature_normalizer in triton deployment is same as my data_collector in training.
So that my MLPModel gets the same data I used it in training and accurately predicts phone or no phone (which I test in @debug_pipeline.py)

Issue:
Your MLP was trained on keypoints normalized around the neck with shoulder/hip scale (from data_collector.py), but in Triton you were passing it raw simcc_x/simcc_y argmaxes with a different normalization. The features at inference didn’t match the features used for training → so the MLP output looked like garbage.

Fix:
Update your feature_normalizer in Triton to replicate the exact same normalization logic from data_collector.py:

Decode simcc_x/simcc_y into keypoints with confidence.

Center around the neck (mid-shoulders).

Scale by shoulder/hip distance.

Append confidence → final 51-dim vector.

That way, the MLP sees the same kind of input it was trained on.

Because it was working when I was training but now it isnt.
So either the problem is that RTMDet and RTMPose (used in triton) is different from MMPoseInferencer(human) that I used in training (in that case I need to retrain based on my Triton Server config)
    Verify This (I have and found it does use RTMPose and RTMDet so this should be fine)

Or there is an actual mismatch between how I'm passing the data to my MLPDetector (data_collector.py in training and feature_normalizer/1/model.py in triton) so I need to match those to make sure it works and predicts correctly.
